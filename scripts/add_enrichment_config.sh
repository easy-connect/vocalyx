#!/bin/bash
# add_enrichment_config.sh
# Ajoute la section [ENRICHMENT] dans config.ini

set -e

CONFIG_FILE="${1:-config.ini}"

echo "ðŸ”§ Ajout de la section [ENRICHMENT] dans $CONFIG_FILE"
echo ""

# VÃ©rifier que le fichier existe
if [ ! -f "$CONFIG_FILE" ]; then
    echo "âŒ Fichier non trouvÃ©: $CONFIG_FILE"
    exit 1
fi

# VÃ©rifier si la section existe dÃ©jÃ 
if grep -q "\[ENRICHMENT\]" "$CONFIG_FILE"; then
    echo "âš ï¸  La section [ENRICHMENT] existe dÃ©jÃ  dans $CONFIG_FILE"
    echo "Aucune modification effectuÃ©e."
    exit 0
fi

# CrÃ©er un backup
BACKUP_FILE="${CONFIG_FILE}.backup.$(date +%Y%m%d_%H%M%S)"
cp "$CONFIG_FILE" "$BACKUP_FILE"
echo "âœ… Backup crÃ©Ã©: $BACKUP_FILE"

# Ajouter la section ENRICHMENT
cat >> "$CONFIG_FILE" << 'EOF'


# =====================================================================
# MODULE D'ENRICHISSEMENT (LLM)
# =====================================================================

[ENRICHMENT]
# Activer/dÃ©sactiver l'enrichissement automatique
enabled = true

# === Worker Settings ===
# Intervalle de polling (en secondes)
# Le worker vÃ©rifie toutes les X secondes s'il y a des transcriptions Ã  enrichir
poll_interval_seconds = 15

# Nombre de transcriptions Ã  traiter par batch
batch_size = 3

# Nombre de tentatives en cas d'erreur
max_retries = 3

# DÃ©lai entre les tentatives (en secondes)
retry_delay_seconds = 60

# === Model Settings ===
# Chemin vers le modÃ¨le LLM (format GGUF)
# TÃ©lÃ©chargez-le avec: make download-model
model_path = models/mistral-7b-instruct-v0.3.Q4_K_M.gguf

# Type de modÃ¨le (pour les templates de prompts)
# Options: mistral, llama, generic
model_type = mistral

# Taille du contexte (nombre de tokens)
# Plus grand = peut traiter de plus longs textes, mais plus lent
# RecommandÃ©: 2048-4096
n_ctx = 4096

# Nombre de threads CPU pour l'infÃ©rence
# RecommandÃ©: nombre de cÅ“urs CPU - 2
n_threads = 6

# Taille du batch pour le traitement
# Plus grand = plus rapide mais plus de RAM
n_batch = 512

# === Generation Settings ===
# Temperature (0.0-1.0)
# 0.0 = dÃ©terministe, 1.0 = crÃ©atif
# RecommandÃ©: 0.3 pour de la gÃ©nÃ©ration factuelle
temperature = 0.3

# Top P (0.0-1.0)
# Sampling nucleus - garde les tokens les plus probables
top_p = 0.9

# Top K
# Nombre de tokens considÃ©rÃ©s pour le sampling
top_k = 40

# Repeat penalty (1.0+)
# PÃ©nalise la rÃ©pÃ©tition de tokens
repeat_penalty = 1.1

# Nombre maximum de tokens Ã  gÃ©nÃ©rer
# Plus = rÃ©sumÃ©s plus longs mais plus lent
max_tokens = 500

# === Processing Limits ===
# Longueur maximale du texte de transcription (en caractÃ¨res)
# Les textes plus longs seront tronquÃ©s
max_transcription_chars = 15000

# Longueur minimale pour enrichir une transcription
# En dessous, l'enrichissement est ignorÃ©
min_transcription_chars = 100

# === Features ===
# Activer/dÃ©sactiver les fonctionnalitÃ©s d'enrichissement
generate_title = true
generate_summary = true
generate_bullets = true
generate_sentiment = true
generate_topics = false

# === Language ===
# Langue des prompts et de la gÃ©nÃ©ration
# Options: fr, en
prompt_language = fr
output_language = fr


# =====================================================================
# PRESETS D'ENRICHISSEMENT
# =====================================================================
#
# ðŸš€ RAPIDE (pour tests ou gros volumes)
# ---------------------------------------------------------------------
# model_path = models/mistral-7b-instruct-v0.3.Q4_K_M.gguf
# n_ctx = 2048
# n_threads = 8
# temperature = 0.2
# max_tokens = 300
# batch_size = 5
#
# âš–ï¸ Ã‰QUILIBRÃ‰ (recommandÃ© pour production)
# ---------------------------------------------------------------------
# model_path = models/mistral-7b-instruct-v0.3.Q4_K_M.gguf
# n_ctx = 4096
# n_threads = 6
# temperature = 0.3
# max_tokens = 500
# batch_size = 3
#
# ðŸŽ¯ QUALITÃ‰ MAXIMALE (enrichissement de qualitÃ©)
# ---------------------------------------------------------------------
# model_path = models/mistral-7b-instruct-v0.3.Q5_K_M.gguf (modÃ¨le plus gros)
# n_ctx = 8192
# n_threads = 4
# temperature = 0.4
# max_tokens = 700
# batch_size = 1
# generate_topics = true
#
# =====================================================================
EOF

echo ""
echo "âœ… Section [ENRICHMENT] ajoutÃ©e avec succÃ¨s!"
echo ""
echo "ðŸ“‹ Prochaines Ã©tapes:"
echo "  1. TÃ©lÃ©charger le modÃ¨le LLM:"
echo "     make download-model"
echo ""
echo "  2. CrÃ©er les tables de la base de donnÃ©es:"
echo "     make db-migrate"
echo ""
echo "  3. Lancer le worker d'enrichissement:"
echo "     make run-enrichment"
echo ""
echo "ðŸ’¡ Pour personnaliser la configuration:"
echo "   nano $CONFIG_FILE"
echo ""